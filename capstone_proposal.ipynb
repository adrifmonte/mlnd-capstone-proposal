{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Proposal\n",
    "\n",
    "Adriano Falsarella Monte\n",
    "\n",
    "August 7th, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Background\n",
    "\n",
    "[comment]: # (_approx. 1-2 paragraphs_)\n",
    "\n",
    "[comment]: # (In this section, provide brief details on the background information of the domain from which the project is proposed. Historical information relevant to the project should be included. It should be clear how or why a problem in the domain can or should be solved. Related academic research should be appropriately cited in this section, including why that research is relevant. Additionally, a discussion of your personal motivation for investigating a particular problem in the domain is encouraged but not required.)\n",
    "\n",
    "What is a fair offer to place when selling or buying a home? How to efficiently come to that fair price? The real estate area has been adopting machine learning to analyse historical data in that market and use several criterias to find a well balanced model to help predicting house prices.\n",
    "\n",
    "Personally, my main motivation for this particular problem is that I've talked to Loft's CTO in a local event at Sao Paulo - Brazil, and I've found out that [Loft uses machine learning to predict the house prices](https://blog.loft.com.br/entenda-como-a-loft-chega-no-valor-de-um-apartamento/) in their business, and it is a core value. I already knew about the [house prices kaggle getting started competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques), but it hadn't took my attention until that moment. I realized it wasn't just a getting started challenge, it is actually a real world problem that real world companies need to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "[comment]: # (_approx. 1 paragraph_)\n",
    "\n",
    "[comment]: # (In this section, clearly describe the problem that is to be solved. The problem described should be well defined and should have at least one relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable {the problem can be expressed in mathematical or logical terms}, measurable {the problem can be measured by some metric and clearly observed}, and replicable {the problem can be reproduced and occurs more than once}.)\n",
    "\n",
    "Given a dataset publicly available at [Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) of homes in Ames - Iowa, having 79 house features, and containing 1460 entry points for training and 1459 entry points for testing, build the best model to predict house sale prices. A great model will predict the house prices as closest as possible to its actual labelled price. The metric used as [evaluation](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/evaluation) is the root mean squared error between the predicted log price and the actual labelled log price, so we have an error scaling equallity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Inputs\n",
    "\n",
    "[comment]: # (_approx. 2-3 paragraphs_)\n",
    "\n",
    "[comment]: # (In this section, the dataset and/or input being considered for the project should be thoroughly described, such as how they relate to the problem and why they should be used. Information such as how the dataset or input is {or was} obtained, and the characteristics of the dataset or input, should be included with relevant references and citations as necessary It should be clear how the dataset or input will be used in the project and whether their use is appropriate given the context of the problem.)\n",
    "\n",
    "It is reasonable that to predict a house price, a model should be trained with historical data about houses features and the price that they were sold. Despite that the houses in Ames - Iowa are different from the houses here in Brazil, the [dataset provided in Kaggle's House Prices competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) would still get the essence of the work that should be done if the data was from a different location since most of the features would also be applicable in different contexts.\n",
    "\n",
    "The dataset is very feature-detailed, providing several characteristics about the dataset's houses, such as: the sale price in dollars (target variable), the date, type, and condition of the sale, the building class, the zoning class, the lot area in square feet, the street acccess type and road proximity, the property configuration, shape, and slope, neighborhood quality, dwelling type and style, the property's condition and material quality, the construction and remodeling date, infos about the property's roof, foundation, electrical system, exterior, masonry veneer, garage, pool, porch, deck, and basement, the property's heating, fireplace, and air conditioning quality, infos about the rooms like bathrooms, bedroom, and kitchen, and finally how functional the home is overall.\n",
    "\n",
    "Lots of the features are categorical, some of them are nominal like types, styles, and shapes, and they should be one-hot-encoded, but there are also some categorical values that are ordinal, that may be ordered and transformed into numberical values, like class, grades, quality. One point of attention is that some nominal features may look ordinal, but we shouldn't be biased in this decision, because not always a category that looks better than another would mean that it is in fact better in the datapoints.\n",
    "\n",
    "There are also lots of numerical values, some of them are continuous like dollars, area, distance, and some of them are discrete like quantity, year, month. They may have their values scaled, or possibly put into categories like 'Close' vs 'Far' or 'Old' vs 'New' and then one-hot-encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Statement\n",
    "\n",
    "[comment]: # (_approx. 1 paragraph_)\n",
    "\n",
    "[comment]: # (In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset or input given. Additionally, describe the solution thoroughly such that it is clear that the solution is quantifiable {the solution can be expressed in mathematical or logical terms}, measurable {the solution can be measured by some metric and clearly observed}, and replicable {the solution can be reproduced and occurs more than once}.)\n",
    "\n",
    "In the conversation I had with Loft's CTO, he told me that with the house's dataset, they make some clusters, and for each cluster they apply a separate linear regression. I loved how it embraces both unsupervised and supervised learning to get a refined result, and I want to try it out, exercising both concepts in this course Capstone proposal.\n",
    "\n",
    "The idea is to get the transformed data as described in the section above, find the best number of clusters in it, and then for each cluster we train the best linear regression model. With the trained models, to make a prediction, we need to first predict which cluster it is better represented, and then use that cluster's trained linear regression model to predict the house price.\n",
    "\n",
    "To make all these training and predicting processes replicable, we'll use a fixed [training and testing data as provided by Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data). Furthermore, in the training, we should always set a constant `random_state` when applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model\n",
    "_(approximately 1-2 paragraphs)_\n",
    "\n",
    "In this section, provide the details for a benchmark model or result that relates to the domain, problem statement, and intended solution. Ideally, the benchmark model or result contextualizes existing methods or known information in the domain and problem given, which could then be objectively compared to the solution. Describe how the benchmark model or result is measurable (can be measured by some metric and clearly observed) with thorough detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "[comment]: # (_approx. 1-2 paragraphs_)\n",
    "\n",
    "[comment]: # (In this section, propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric{s} you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric{s} are derived and provide an example of their mathematical representations {if applicable}. Complex evaluation metrics should be clearly defined and quantifiable {can be expressed in mathematical or logical terms}.)\n",
    "\n",
    "There are many evaluation methods available in scikit learn in the [`sklearn.metrics`](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics) package. As per the proposed solution, we'll have to take at least one [clustering metric](https://scikit-learn.org/stable/modules/classes.html#clustering-metrics) and at least one [regression metric](https://scikit-learn.org/stable/modules/classes.html#regression-metrics).\n",
    "\n",
    "For the clustering part the idea is to use the silhouette score as the metric to find the best number of clusters, since it's the one that we've used most in the course. This evaluation method is provided by scikit learn in [`sklearn.metrics.silhouette_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html) module.\n",
    "\n",
    "For the regression part the suggestion is to use the mean squared log error as the metric to find the best regression model, since it's the one that Kaggle will use in the [Leaderboard ranking](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/leaderboard). This evaluation method is also provided by scikit learn in [`sklearn.metrics.mean_squared_log_error`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html) module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Design\n",
    "_(approx. 1 page)_\n",
    "\n",
    "In this final section, summarize a theoretical workflow for approaching a solution given the problem. Provide thorough discussion for what strategies you may consider employing, what analysis of the data might be required before being used, or which algorithms will be considered for your implementation. The workflow and discussion that you provide should align with the qualities of the previous sections. Additionally, you are encouraged to include small visualizations, pseudocode, or diagrams to aid in describing the project design, but it is not required. The discussion should clearly outline your intended workflow of the capstone project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before submitting your proposal, ask yourself. . .**\n",
    "\n",
    "- Does the proposal you have written follow a well-organized structure similar to that of the project template?\n",
    "- Is each section (particularly **Solution Statement** and **Project Design**) written in a clear, concise and specific fashion? Are there any ambiguous terms or phrases that need clarification?\n",
    "- Would the intended audience of your project be able to understand your proposal?\n",
    "- Have you properly proofread your proposal to assure there are minimal grammatical and spelling mistakes?\n",
    "- Are all the resources used for this project correctly cited and referenced?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
